# update_playlist.py
import requests
import re
import os
import time

# é…ç½®ä¿¡æ¯ï¼ˆå…ˆä¸ç®¡Gistæ›´æ–°ï¼‰
GIST_ID = "1eefb097a9b3ec25c79bbd4149066d41"
GH_TOKEN = os.environ['GH_PAT']

def debug_fetch_kbs_live_url(ch_code, channel_name):
    """
    è°ƒè¯•ç‰ˆæœ¬çš„KBSæŠ“å–å‡½æ•° - è¯¦ç»†è¾“å‡ºæŠ“å–è¿‡ç¨‹
    """
    try:
        url = f"https://onair.kbs.co.kr/index.html?sname=onair&stype=live&ch_code={ch_code}&ch_type=globalList"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://onair.kbs.co.kr/'
        }
        
        print(f"\nğŸ” å¼€å§‹æŠ“å– {channel_name}...")
        print(f"   ç›®æ ‡URL: {url}")
        
        response = requests.get(url, headers=headers, timeout=20)
        print(f"   ç½‘é¡µè¯·æ±‚çŠ¶æ€: {response.status_code}")
        
        # ä¿å­˜ç½‘é¡µå†…å®¹ç”¨äºåˆ†æï¼ˆè°ƒè¯•ç”¨ï¼‰
        webpage_content = response.text
        print(f"   ç½‘é¡µå¤§å°: {len(webpage_content)} å­—ç¬¦")
        
        # æ˜¾ç¤ºç½‘é¡µå‰500ä¸ªå­—ç¬¦ï¼ˆçœ‹æ˜¯å¦åŒ…å«è§†é¢‘ç›¸å…³å…ƒç´ ï¼‰
        preview = webpage_content[:500]
        print(f"   ç½‘é¡µé¢„è§ˆ: {preview}...")
        
        # å¤šç§åŒ¹é…æ¨¡å¼
        patterns = [
            r'https?://[^\s"\']*?\.m3u8[^\s"\']*',
            r'file\s*:\s*["\'](https?://[^"\']*?\.m3u8[^"\']*?)["\']',
            r'src\s*:\s*["\'](https?://[^"\']*?\.m3u8[^"\']*?)["\']',
            r'videoUrl\s*:\s*["\'](https?://[^"\']*?\.m3u8[^"\']*?)["\']',
            r'streamUrl\s*:\s*["\'](https?://[^"\']*?\.m3u8[^"\']*?)["\']',
        ]
        
        found_links = []
        for i, pattern in enumerate(patterns):
            matches = re.findall(pattern, webpage_content, re.IGNORECASE)
            print(f"   æ¨¡å¼{i+1}æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            
            for match in matches:
                clean_link = match.replace('\\/', '/').replace('\\u002F', '/')
                if '.m3u8' in clean_link:
                    found_links.append(clean_link)
                    print(f"     â†’ æ‰¾åˆ°M3U8: {clean_link[:80]}...")
        
        print(f"   æ€»å…±æ‰¾åˆ° {len(found_links)} ä¸ªM3U8é“¾æ¥")
        
        # åˆ†ææ‰¾åˆ°çš„é“¾æ¥
        if found_links:
            print(f"   ğŸ” åˆ†æé“¾æ¥ç‰¹å¾:")
            for i, link in enumerate(found_links):
                kbs_keyword = "æœ‰kbså…³é”®è¯" if 'kbs' in link.lower() else "æ— kbså…³é”®è¯"
                print(f"     {i+1}. {kbs_keyword}: {link[:60]}...")
            
            # ä¼˜å…ˆé€‰æ‹©åŒ…å«é¢‘é“å…³é”®è¯çš„é“¾æ¥
            for link in found_links:
                if f'kbs{ch_code}' in link.lower() or 'kbs' in link.lower():
                    print(f"   âœ… é€‰æ‹©æœ€ä½³é“¾æ¥ï¼ˆå«kbså…³é”®è¯ï¼‰")
                    return link
            
            # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„é“¾æ¥
            print(f"   âš ï¸ ä½¿ç”¨é¦–ä¸ªæ‰¾åˆ°çš„é“¾æ¥")
            return found_links[0]
        else:
            print(f"   âŒ æœªæ‰¾åˆ°ä»»ä½•M3U8é“¾æ¥")
            return None
            
    except Exception as e:
        print(f"   âŒ æŠ“å–è¿‡ç¨‹å‡ºé”™: {e}")
        return None

def debug_fetch_mbn_live_url():
    """
    è°ƒè¯•ç‰ˆæœ¬çš„MBNæŠ“å–å‡½æ•°
    """
    try:
        url = "https://www.mbn.co.kr/vod/onair"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://www.mbn.co.kr/'
        }
        
        print(f"\nğŸ” å¼€å§‹æŠ“å– MBN...")
        print(f"   ç›®æ ‡URL: {url}")
        
        response = requests.get(url, headers=headers, timeout=20)
        print(f"   ç½‘é¡µè¯·æ±‚çŠ¶æ€: {response.status_code}")
        
        webpage_content = response.text
        print(f"   ç½‘é¡µå¤§å°: {len(webpage_content)} å­—ç¬¦")
        
        # æ˜¾ç¤ºç½‘é¡µå‰500ä¸ªå­—ç¬¦
        preview = webpage_content[:500]
        print(f"   ç½‘é¡µé¢„è§ˆ: {preview}...")
        
        patterns = [
            r'https?://[^\s"\']*?\.m3u8[^\s"\']*',
            r'file\s*:\s*["\'](https?://[^"\']*?\.m3u8[^"\']*?)["\']',
            r'videoUrl\s*:\s*["\'](https?://[^"\']*?\.m3u8[^"\']*?)["\']',
        ]
        
        found_links = []
        for i, pattern in enumerate(patterns):
            matches = re.findall(pattern, webpage_content, re.IGNORECASE)
            print(f"   æ¨¡å¼{i+1}æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            
            for match in matches:
                clean_link = match.replace('\\/', '/')
                if '.m3u8' in clean_link:
                    found_links.append(clean_link)
                    print(f"     â†’ æ‰¾åˆ°M3U8: {clean_link[:80]}...")
        
        print(f"   æ€»å…±æ‰¾åˆ° {len(found_links)} ä¸ªM3U8é“¾æ¥")
        
        if found_links:
            print(f"   ğŸ” åˆ†æé“¾æ¥ç‰¹å¾:")
            for i, link in enumerate(found_links):
                mbn_keyword = "æœ‰mbnå…³é”®è¯" if 'mbn' in link.lower() else "æ— mbnå…³é”®è¯"
                print(f"     {i+1}. {mbn_keyword}: {link[:60]}...")
            
            # ä¼˜å…ˆé€‰æ‹©åŒ…å«mbnå…³é”®è¯çš„é“¾æ¥
            for link in found_links:
                if 'mbn' in link.lower():
                    print(f"   âœ… é€‰æ‹©æœ€ä½³é“¾æ¥ï¼ˆå«mbnå…³é”®è¯ï¼‰")
                    return link
            
            print(f"   âš ï¸ ä½¿ç”¨é¦–ä¸ªæ‰¾åˆ°çš„é“¾æ¥")
            return found_links[0]
        else:
            print(f"   âŒ æœªæ‰¾åˆ°ä»»ä½•M3U8é“¾æ¥")
            return None
            
    except Exception as e:
        print(f"   âŒ æŠ“å–è¿‡ç¨‹å‡ºé”™: {e}")
        return None

def main():
    print("=" * 60)
    print("ğŸ”¬ è‡ªåŠ¨æŠ“å–åŠŸèƒ½è°ƒè¯•æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•è‡ªåŠ¨æŠ“å–åŠŸèƒ½
    print("\nğŸ¯ é˜¶æ®µä¸€ï¼šæµ‹è¯•è‡ªåŠ¨æŠ“å–åŠŸèƒ½")
    
    kbs1_url = debug_fetch_kbs_live_url('11', 'KBS 1TV')
    kbs2_url = debug_fetch_kbs_live_url('12', 'KBS 2TV') 
    mbn_url = debug_fetch_mbn_live_url()
    
    print(f"\nğŸ“Š æŠ“å–ç»“æœæ±‡æ€»:")
    print(f"   KBS 1TV: {'âœ… ' + kbs1_url[:50] + '...' if kbs1_url else 'âŒ æŠ“å–å¤±è´¥'}")
    print(f"   KBS 2TV: {'âœ… ' + kbs2_url[:50] + '...' if kbs2_url else 'âŒ æŠ“å–å¤±è´¥'}")
    print(f"   MBN:     {'âœ… ' + mbn_url[:50] + '...' if mbn_url else 'âŒ æŠ“å–å¤±è´¥'}")
    
    # å¤‡ç”¨é“¾æ¥
    backup_links = {
        'kbs1': 'https://1tv.gscdn.kbs.co.kr/1tv_3.m3u8',
        'kbs2': 'https://2tv.gscdn.kbs.co.kr/2tv_1.m3u8',
        'mbn': 'https://hls-live.mbn.co.kr/mbn-on-air/600k/chunklist.m3u8'
    }
    
    # åº”ç”¨å¤‡ç”¨é“¾æ¥
    final_kbs1 = kbs1_url or backup_links['kbs1']
    final_kbs2 = kbs2_url or backup_links['kbs2'] 
    final_mbn = mbn_url or backup_links['mbn']
    
    print(f"\nğŸ¯ æœ€ç»ˆä½¿ç”¨çš„é“¾æ¥:")
    print(f"   KBS 1TV: {final_kbs1[:80]}...")
    print(f"   KBS 2TV: {final_kbs2[:80]}...")
    print(f"   MBN:     {final_mbn[:80]}...")
    
    # ç®€åŒ–çš„Gistæ›´æ–°ï¼ˆé¿å…404å¹²æ‰°æµ‹è¯•ï¼‰
    print(f"\nğŸ“¤ è·³è¿‡Gistæ›´æ–°ï¼Œä¸“æ³¨æŠ“å–åŠŸèƒ½æµ‹è¯•")
    print("ğŸ‰ è‡ªåŠ¨æŠ“å–åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()
